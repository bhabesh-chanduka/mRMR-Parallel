{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3750)\n",
      "Time 0.031332969665527344\n",
      "[37, 27, 80, 61, 47, 51, 10, 28, 54, 25, 4, 63, 26, 14, 53, 93, 6, 42, 11, 96]\n"
     ]
    }
   ],
   "source": [
    "%%cython --compile-args=-fopenmp --link-args=-fopenmp --force\n",
    "# cython : boundscheck = False\n",
    "cimport numpy as np\n",
    "from cython.parallel import prange\n",
    "import time\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.datasets import make_classification\n",
    "import multiprocessing\n",
    "from libc.stdlib cimport malloc, free\n",
    "\n",
    "global X,Y\n",
    "global classes, num_features, num_samples, num_relevant_features\n",
    "cpdef int cpu_count\n",
    "cpdef int num_threads\n",
    "\n",
    "cpdef make_dataset(int num_classes, int num_features, int num_samples, int useful_features):\n",
    "    x,y = make_classification(n_samples=num_samples,n_classes=num_classes,n_informative=useful_features,n_features=num_features)\n",
    "    return x,y \n",
    "\n",
    "cdef double pearson_correlation(double *X, int *Y, int n) nogil:\n",
    "    cdef double sig_x = 0.0, sig_y = 0.0 ,sig_xy = 0.0, sig_x2 = 0.0, sig_y2 = 0.0\n",
    "    for i in range(n):\n",
    "        sig_x += X[i]\n",
    "        sig_y += Y[i]\n",
    "        sig_xy += X[i]*Y[i]\n",
    "        sig_x2 += (X[i]*X[i])\n",
    "        sig_y2 += (Y[i]*Y[i])\n",
    "    cdef double ans =((n*sig_xy -sig_x*sig_y)/(((n*sig_x2-sig_x**2)*(n*sig_y2-sig_y**2))**0.5))\n",
    "    if ans < 0 :\n",
    "        ans *= -1\n",
    "    return ans\n",
    "\n",
    "cdef double pearson_correlation2(double *X, double *Y, int n) nogil:\n",
    "    cdef double sig_x = 0.0, sig_y = 0.0 ,sig_xy = 0.0, sig_x2 = 0.0, sig_y2 = 0.0\n",
    "    for i in range(n):\n",
    "        sig_x += X[i]\n",
    "        sig_y += Y[i]\n",
    "        sig_xy += X[i]*Y[i]\n",
    "        sig_x2 += (X[i]*X[i])\n",
    "        sig_y2 += (Y[i]*Y[i])\n",
    "    cdef double ans =((n*sig_xy -sig_x*sig_y)/(((n*sig_x2-sig_x**2)*(n*sig_y2-sig_y**2))**0.5))\n",
    "    if ans < 0 :\n",
    "        ans *= -1\n",
    "    return ans\n",
    "\n",
    "cdef double Redundancy(int target, int *S, double **redundancy, int ls) nogil:\n",
    "    cdef double ans = 0.0\n",
    "    cdef int i\n",
    "    for i in range(ls):\n",
    "        ans+= redundancy[target][S[i]]\n",
    "    return ans\n",
    "    \n",
    "    \n",
    "cpdef select_k_features(np.ndarray[double, ndim=2, mode='c'] x_train, np.ndarray y_train, int k):\n",
    "    cdef double* relevance = <double*> malloc((num_features)* sizeof(double)) # edit : num_features+1\n",
    "    cdef double **x_train_ = <double**>malloc((num_features)*sizeof(double*))\n",
    "    cdef double **redundancy = <double**> malloc((num_features)*sizeof(double*))\n",
    "    cdef int *y_train_ = <int*> y_train.data\n",
    "    cdef int *S = <int*> malloc((k)*sizeof(int*)) #stores the set of all features currently selected\n",
    "    cdef int i\n",
    "    for i in range(num_features):\n",
    "        x_train_[i] = &x_train[i,0]\n",
    "        redundancy[i] = <double*> malloc ((num_features)*sizeof(double))\n",
    "    cdef int num_feature = x_train.shape[0]\n",
    "    cdef int n = x_train.shape[1]\n",
    "    cdef int num_thread = num_threads\n",
    "    with nogil: # parallel calculation of relevances\n",
    "        for i in prange(num_feature, schedule='guided', num_threads=num_thread):\n",
    "            relevance[i] = (pearson_correlation(x_train_[i],y_train_,n))\n",
    "    feature_list = []\n",
    "    cdef int max_relevance = 0\n",
    "    for i in range(1,num_feature): #select the one with the highest relevance\n",
    "        if relevance[i] > relevance[max_relevance]:\n",
    "            max_relevance = i\n",
    "    feature_list.append(max_relevance)\n",
    "    S[0] = max_relevance\n",
    "    with nogil:\n",
    "        for i in prange(num_feature,schedule='guided',num_threads=num_thread):\n",
    "            redundancy[i][max_relevance] = pearson_correlation2(x_train_[i],x_train_[max_relevance],n)\n",
    "            redundancy[max_relevance][i] = redundancy[i][max_relevance]\n",
    "    cdef double total_relevance = relevance[max_relevance]\n",
    "    cdef double total_redundancy = 0.0\n",
    "    cdef int f,l,it,ptr,feature\n",
    "    cdef int* imp_features_list = <int*> malloc((num_feature)*sizeof(int))\n",
    "    cdef double* imp_features = <double*> malloc((num_feature)*sizeof(double))\n",
    "    \n",
    "    for i in range(1,k):\n",
    "        l = num_feature - i # possible candidates  \n",
    "        ptr = 0\n",
    "        for f in range(num_feature):\n",
    "            if f not in feature_list:\n",
    "                imp_features_list[ptr] = f\n",
    "                ptr = ptr+1\n",
    "\n",
    "\n",
    "        with nogil:\n",
    "             for it in prange(l, schedule = 'guided', num_threads = num_thread):\n",
    "                feature = imp_features_list[it]\n",
    "                imp_features[it] = (total_relevance*i+relevance[feature])/(i+1)\n",
    "                imp_features[it]-= (total_redundancy*i*i+Redundancy(feature,S,redundancy,i))/((i+1)**2)\n",
    "        max_relevance = 0\n",
    "       \n",
    "        for it in range(1,l):\n",
    "            if imp_features[it] > imp_features[max_relevance]:\n",
    "                max_relevance = it\n",
    "        \n",
    "        S[i] = imp_features_list[max_relevance]\n",
    "        total_redundancy = (total_redundancy*i*i+Redundancy(imp_features_list[max_relevance],S,redundancy,i))/((i+1)**2)\n",
    "        total_relevance = (total_relevance*i + relevance[imp_features_list[max_relevance]])/(i+1)\n",
    "        feature_list.append(imp_features_list[max_relevance])\n",
    "        max_relevance = imp_features_list[max_relevance]\n",
    "        with nogil:\n",
    "            for it in prange(num_feature,schedule='guided',num_threads=num_thread):\n",
    "                redundancy[it][max_relevance] = pearson_correlation2(x_train_[it],x_train_[max_relevance],n)\n",
    "                redundancy[max_relevance][it] = redundancy[it][max_relevance]\n",
    "    return feature_list\n",
    "    \n",
    "num_classes = 50\n",
    "num_features = 100\n",
    "num_samples = 5000\n",
    "useful_features = 84\n",
    "X,Y = make_classification(n_samples=num_samples,n_classes=num_classes,n_informative=useful_features,n_features=num_features) # Synthesis of dataset\n",
    "x_train,x_test,y_train,y_test = train_test_split(X, Y, test_size = 0.25,random_state = 42)\n",
    "cpu_count = multiprocessing.cpu_count()\n",
    "num_threads = cpu_count\n",
    "n = len(x_train)    \n",
    "k = int(0.2*num_features) # number of features to be selected\n",
    "print(x_train.T.shape)\n",
    "t1 = time.time()\n",
    "selected_features  = select_k_features(x_train.T.copy(order='c'),y_train.T.copy(order='c'),k)\n",
    "print(\"Time\",time.time()-t1)\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
